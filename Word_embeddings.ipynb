{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    One hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8964, 5980, 4592, 9807],\n",
       " [8964, 5980, 4592, 9363],\n",
       " [8964, 2971, 4592, 5203],\n",
       " [4338, 1922, 5016, 6685, 7011],\n",
       " [4338, 1922, 5016, 6685, 3310],\n",
       " [4656, 8964, 6462, 4592, 1124],\n",
       " [8386, 2215, 1355, 6685]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\n",
    "### sentences\n",
    "sent=[  'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good',]\n",
    "\n",
    "## Define the vocabulary size\n",
    "voc_size=10000\n",
    "\n",
    "### One Hot Representation\n",
    "one_hot_repr=[one_hot(words,voc_size)for words in sent] # While doing this one hot encoding technique in keras we pass the parameters as words & vocabulary size.\n",
    "one_hot_repr\n",
    "\n",
    "## Ex - 2172 assigns the index number of the word 'the' in the vocabulary. This means index 2172 is assigned as 1 & other indexes are considered as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedding representaion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 8964 5980 4592 9807]\n",
      " [   0    0    0    0 8964 5980 4592 9363]\n",
      " [   0    0    0    0 8964 2971 4592 5203]\n",
      " [   0    0    0 4338 1922 5016 6685 7011]\n",
      " [   0    0    0 4338 1922 5016 6685 3310]\n",
      " [   0    0    0 4656 8964 6462 4592 1124]\n",
      " [   0    0    0    0 8386 2215 1355 6685]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "\n",
    "sent_length=8 # Step 1 : Make sentences of equal size.\n",
    "embedded_docs=pad_sequences(one_hot_repr,padding='pre',maxlen=sent_length) # Adding some pads before the sentences to make it equal to maximum decided length.\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## feature representation allows to assign selected features to the whole vocabulary. \n",
    "dim=10\n",
    "\n",
    "## Sequential model to use embedding layer.\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,dim,input_length=sent_length)) ## Passing vocabulary size = 10000 , dimmensions/features = 10, sentence length.\n",
    "model.compile('adam','mse') # Output layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.00721078, -0.02232076,  0.00131174, -0.03862607,\n",
       "         -0.00124487,  0.01700391, -0.00288004, -0.02921543,\n",
       "          0.00538623,  0.00024558],\n",
       "        [-0.00414001, -0.03233385,  0.04409924, -0.00944532,\n",
       "          0.03331412,  0.03070984,  0.0421849 ,  0.03064516,\n",
       "         -0.03372888,  0.01382567],\n",
       "        [ 0.01728043,  0.048831  , -0.04643934,  0.01907844,\n",
       "         -0.02417684, -0.02889149,  0.02069653, -0.02984674,\n",
       "         -0.04503554, -0.03554178],\n",
       "        [ 0.02393732,  0.0026402 ,  0.03685561,  0.02350247,\n",
       "          0.03322016,  0.03182835, -0.04811572, -0.0181348 ,\n",
       "          0.00805829, -0.01219798]],\n",
       "\n",
       "       [[ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.00721078, -0.02232076,  0.00131174, -0.03862607,\n",
       "         -0.00124487,  0.01700391, -0.00288004, -0.02921543,\n",
       "          0.00538623,  0.00024558],\n",
       "        [-0.00414001, -0.03233385,  0.04409924, -0.00944532,\n",
       "          0.03331412,  0.03070984,  0.0421849 ,  0.03064516,\n",
       "         -0.03372888,  0.01382567],\n",
       "        [ 0.01728043,  0.048831  , -0.04643934,  0.01907844,\n",
       "         -0.02417684, -0.02889149,  0.02069653, -0.02984674,\n",
       "         -0.04503554, -0.03554178],\n",
       "        [ 0.0122403 ,  0.03672406,  0.04680053,  0.02964832,\n",
       "         -0.04987263, -0.02531115, -0.0202512 , -0.00783049,\n",
       "          0.02574383,  0.03415075]],\n",
       "\n",
       "       [[ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.00721078, -0.02232076,  0.00131174, -0.03862607,\n",
       "         -0.00124487,  0.01700391, -0.00288004, -0.02921543,\n",
       "          0.00538623,  0.00024558],\n",
       "        [-0.00065119,  0.02273175, -0.01881243,  0.00731625,\n",
       "         -0.00932463,  0.01768204,  0.01639863,  0.01863945,\n",
       "          0.02744678,  0.03804967],\n",
       "        [ 0.01728043,  0.048831  , -0.04643934,  0.01907844,\n",
       "         -0.02417684, -0.02889149,  0.02069653, -0.02984674,\n",
       "         -0.04503554, -0.03554178],\n",
       "        [-0.00664688,  0.0257487 ,  0.00037406, -0.04710994,\n",
       "         -0.02022868, -0.03894449, -0.02624497,  0.00815579,\n",
       "          0.01824984,  0.04977696]],\n",
       "\n",
       "       [[ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [-0.04603423, -0.04967257,  0.00580857, -0.02058086,\n",
       "         -0.02387929,  0.02294589,  0.03737589,  0.03615664,\n",
       "         -0.00957463,  0.0253589 ],\n",
       "        [ 0.03923323,  0.00842239, -0.04460633,  0.00634735,\n",
       "          0.04506978,  0.01623288,  0.01344447, -0.02914268,\n",
       "          0.01115266, -0.0252887 ],\n",
       "        [ 0.04721684, -0.00143365, -0.03310861, -0.01454049,\n",
       "          0.01871865,  0.03921952, -0.04789701, -0.04974359,\n",
       "          0.00880859,  0.0089644 ],\n",
       "        [ 0.02964033, -0.03968203, -0.03002135, -0.00407581,\n",
       "         -0.01903048,  0.00032221, -0.02663358,  0.01502163,\n",
       "         -0.04885978, -0.03279813],\n",
       "        [ 0.00274792, -0.04136743, -0.00756945, -0.0097193 ,\n",
       "         -0.02750655,  0.03428384, -0.00519652, -0.01573758,\n",
       "         -0.03914813,  0.00233579]],\n",
       "\n",
       "       [[ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [-0.04603423, -0.04967257,  0.00580857, -0.02058086,\n",
       "         -0.02387929,  0.02294589,  0.03737589,  0.03615664,\n",
       "         -0.00957463,  0.0253589 ],\n",
       "        [ 0.03923323,  0.00842239, -0.04460633,  0.00634735,\n",
       "          0.04506978,  0.01623288,  0.01344447, -0.02914268,\n",
       "          0.01115266, -0.0252887 ],\n",
       "        [ 0.04721684, -0.00143365, -0.03310861, -0.01454049,\n",
       "          0.01871865,  0.03921952, -0.04789701, -0.04974359,\n",
       "          0.00880859,  0.0089644 ],\n",
       "        [ 0.02964033, -0.03968203, -0.03002135, -0.00407581,\n",
       "         -0.01903048,  0.00032221, -0.02663358,  0.01502163,\n",
       "         -0.04885978, -0.03279813],\n",
       "        [ 0.01589065, -0.01643337,  0.04561048,  0.03799688,\n",
       "          0.03605399,  0.0092699 ,  0.03899467, -0.0100977 ,\n",
       "          0.02361021, -0.04905951]],\n",
       "\n",
       "       [[ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [-0.01502658,  0.00723976, -0.00278823, -0.01403123,\n",
       "          0.01107943,  0.04620472, -0.04364289,  0.01718349,\n",
       "          0.00145077, -0.03360625],\n",
       "        [ 0.00721078, -0.02232076,  0.00131174, -0.03862607,\n",
       "         -0.00124487,  0.01700391, -0.00288004, -0.02921543,\n",
       "          0.00538623,  0.00024558],\n",
       "        [-0.04364644, -0.03338385, -0.03580763, -0.00312121,\n",
       "         -0.00649792, -0.04824839,  0.02772183,  0.03412909,\n",
       "          0.02394483,  0.00206604],\n",
       "        [ 0.01728043,  0.048831  , -0.04643934,  0.01907844,\n",
       "         -0.02417684, -0.02889149,  0.02069653, -0.02984674,\n",
       "         -0.04503554, -0.03554178],\n",
       "        [-0.00762274, -0.01362745, -0.03545592,  0.02328268,\n",
       "          0.04529548,  0.0246332 ,  0.00391173,  0.0284848 ,\n",
       "          0.02392921, -0.01473024]],\n",
       "\n",
       "       [[ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [ 0.04750032,  0.03156645, -0.02608144,  0.03784298,\n",
       "          0.00595925,  0.00349509, -0.03521048, -0.02863294,\n",
       "         -0.03503264, -0.03150183],\n",
       "        [-0.01153468,  0.02294277,  0.00861377, -0.00921975,\n",
       "          0.00237343, -0.03219402, -0.00868209, -0.04159132,\n",
       "         -0.01600348, -0.00322358],\n",
       "        [-0.04572105, -0.03165348,  0.03416247, -0.01586225,\n",
       "          0.03797277,  0.0321932 , -0.02370257,  0.03126479,\n",
       "         -0.01222412,  0.03659509],\n",
       "        [ 0.04831168,  0.01348903,  0.01026975, -0.0272403 ,\n",
       "          0.0186297 ,  0.00473509,  0.02549594,  0.01116856,\n",
       "         -0.01637684,  0.04412195],\n",
       "        [ 0.02964033, -0.03968203, -0.03002135, -0.00407581,\n",
       "         -0.01903048,  0.00032221, -0.02663358,  0.01502163,\n",
       "         -0.04885978, -0.03279813]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs) ## Each of the 10,000 words are assigned to 10 unique features & the values show the relation between them.\n",
    "## (Ex - one of our feature is Gender then how does it associates with a word mentioned in vocabulary.There could be some huge relations or else negative or no correlation.  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0, 8964, 5980, 4592, 9807])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0] ## Sentence 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
